{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
      "Accuracy on test set by our model       :   67.1875\n",
      "Accuracy on test set by sklearn model   :   80.46875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\" )\n",
    "  \n",
    "# to compare our model's accuracy with sklearn model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression\n",
    "class LogitRegression() :\n",
    "    def __init__( self, learning_rate, iterations ) :        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training    \n",
    "    def fit( self, X, Y ) :        \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        self.m, self.n = X.shape        \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        # calculate gradients        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y\n",
    "  \n",
    "  \n",
    "# Driver code\n",
    "  \n",
    "def main() :\n",
    "      \n",
    "    # Importing dataset    \n",
    "    df = pd.read_csv( \"diabetes.csv\" )\n",
    "    X = df.iloc[:,:-1].values\n",
    "    Y = df.iloc[:,-1:].values\n",
    "    print(X)\n",
    "    # Splitting dataset into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "      X, Y, test_size = 1/3, random_state = 0 )\n",
    "      \n",
    "    # Model training    \n",
    "    model = LogitRegression( learning_rate = 0.01, iterations = 1000 )\n",
    "      \n",
    "    model.fit( X_train, Y_train )    \n",
    "    model1 = LogisticRegression()    \n",
    "    model1.fit( X_train, Y_train)\n",
    "      \n",
    "    # Prediction on test set\n",
    "    Y_pred = model.predict( X_test )    \n",
    "    Y_pred1 = model1.predict( X_test )\n",
    "      \n",
    "    # measure performance    \n",
    "    correctly_classified = 0    \n",
    "    correctly_classified1 = 0\n",
    "      \n",
    "    # counter    \n",
    "    count = 0    \n",
    "    for count in range( np.size( Y_pred ) ) :  \n",
    "        \n",
    "        if Y_test[count] == Y_pred[count] :            \n",
    "            correctly_classified = correctly_classified + 1\n",
    "          \n",
    "        if Y_test[count] == Y_pred1[count] :            \n",
    "            correctly_classified1 = correctly_classified1 + 1\n",
    "              \n",
    "        count = count + 1\n",
    "          \n",
    "    print( \"Accuracy on test set by our model       :  \", ( \n",
    "      correctly_classified / count ) * 100 )\n",
    "    print( \"Accuracy on test set by sklearn model   :  \", ( \n",
    "      correctly_classified1 / count ) * 100 )\n",
    "  \n",
    "  \n",
    "if __name__ == \"__main__\" :     \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
